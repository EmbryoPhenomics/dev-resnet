{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cf340b0-c6f8-4087-a8bf-9d1578aa0a58",
   "metadata": {},
   "source": [
    "# Training notebook for training and evaluating the Dev-ResNet model \n",
    "\n",
    "A notebook outlining the training and evaluation procedure for Dev-ResNet. Note that this is specifically for a dataset comprising developmental sequences of the great pond snail, Lymnaea stagnalis.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "The following are required dependencies for this script. We also set up mixed precision training for the speedup it provides in training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b0294-dc38-40e5-afc4-9625a62eebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import vuba\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "import atexit\n",
    "import time\n",
    "import os\n",
    "import ujson\n",
    "import math\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "from dev_resnet import DevResNet\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    " \n",
    "# Parameters ----------------------------------------------------------\n",
    "batch_size = 32\n",
    "input_shape = (12,128,128,1)\n",
    "epochs = 50\n",
    "model_save_dir = './trained_models'\n",
    "model_name = 'Dev-Resnet_lymnaea'\n",
    "events = ['pre_gastrula', 'gastrula', 'trocophore', 'veliger', 'eye', 'heart', 'crawling', 'radula', 'hatch', 'dead']\n",
    "\n",
    "train_data_path = './annotations_train_aug.csv'\n",
    "val_data_path = './annotations_val.csv'\n",
    "test_data_path = './annotations_test.csv'\n",
    "\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab75518a-3e84-4258-b80a-6f68a135711f",
   "metadata": {},
   "source": [
    "## Dataset pipeline\n",
    "\n",
    "The following dataset pipeline is for an augmented dataset generated from manually annotated developmental sequences of *Lymnaea stagnalis*. Note that images are rescaled by default in the model so images can be supplied in uint8 format.\n",
    "\n",
    "If you wish to train Dev-ResNet on this video dataset, please download and extract the following dataset into the same folder as this notebook: https://zenodo.org/record/8214975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612dc7c4-dcf9-48d2-81b7-a1a93ed80e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(fn, label):\n",
    "    gif = tf.io.read_file(fn)\n",
    "    gif = tf.image.decode_gif(gif)\n",
    "    gif = tf.image.resize_with_pad(gif, 128, 128)\n",
    "    gif = tf.image.rgb_to_grayscale(gif)\n",
    "    return gif, label\n",
    "\n",
    "def dataset(images, labels, batch_size): \n",
    "    data = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    data = data.map(read_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    data = data.batch(batch_size, drop_remainder=True)\n",
    "    return data\n",
    "\n",
    "annotations_train = pd.read_csv(train_data_path)\n",
    "annotations_train = annotations_train.sample(frac=1).reset_index(drop=True)\n",
    "annotations_train['categorical'] = [events.index(e) for e in annotations_train.single_event]\n",
    "\n",
    "annotations_val = pd.read_csv(val_data_path)\n",
    "annotations_val = annotations_val.sample(frac=1).reset_index(drop=True)\n",
    "annotations_val['categorical'] = [events.index(e) for e in annotations_val.single_event]\n",
    "\n",
    "annotations_test = pd.read_csv(test_data_path)\n",
    "annotations_test['categorical'] = [events.index(e) for e in annotations_test.single_event]\n",
    "\n",
    "# Training data pipeline\n",
    "train_files = list(annotations_train.out_file)\n",
    "train_labels = list(annotations_train.categorical)\n",
    "\n",
    "val_files = list(annotations_val.out_file)\n",
    "val_labels = list(annotations_val.categorical)\n",
    "\n",
    "# Test data pipeline\n",
    "test_files = list(annotations_test.out_file)\n",
    "test_labels = list(annotations_test.categorical)\n",
    "\n",
    "train_data = dataset(train_files, train_labels, batch_size)\n",
    "val_data = dataset(val_files, val_labels, batch_size)   \n",
    "test_data = dataset(test_files, test_labels, batch_size)\n",
    "\n",
    "for b in train_data:\n",
    "    images, labels = b\n",
    "    print(images.shape)\n",
    "    print(labels)\n",
    "    break\n",
    "\n",
    "# 4x4 grid for batch size of 32\n",
    "fig = plt.figure(figsize=(8., 8.))\n",
    "grid = ImageGrid(fig, 111,\n",
    "             nrows_ncols=(4, 4),\n",
    "             axes_pad=0.3,\n",
    ")\n",
    "\n",
    "for i, (v, f, ax) in enumerate(zip(images, labels, grid)):\n",
    "\n",
    "    im = v[0,:,:,0]\n",
    "    event = events[f]\n",
    "    \n",
    "    ax.set_title(event)\n",
    "    ax.imshow(im, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc34a3ef-0381-480f-95f2-d9be20d75a67",
   "metadata": {},
   "source": [
    "## Training and evaluation\n",
    "\n",
    "This is the main training loop for constructing, training and computing summary metrics for Dev-ResNet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ede1f0-332f-40ab-a7a2-ef73554589ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate with three different seeds for computing metrics\n",
    "for i in range(3):\n",
    "    np.random.seed(i)\n",
    "    tf.random.set_seed(i)\n",
    "    \n",
    "    model = DevResNet(input_shape, n_classes=len(events))\n",
    "\n",
    "    model.compile(\n",
    "        # Fixed learning rate of 1e-6 works particularly well for convergence after 50 epochs\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.000001), \n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    class EvaluateCallback(keras.callbacks.Callback):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.loss = []\n",
    "            self.accuracy = []\n",
    "\n",
    "        def on_epoch_end(self, epoch, log=None):\n",
    "            loss, acc = self.model.evaluate(test_data, verbose=0)\n",
    "            print('-', 'test_loss:', round(loss, 4), 'test_accuracy:', round(acc, 4))\n",
    "            self.loss.append(loss)\n",
    "            self.accuracy.append(acc)\n",
    "\n",
    "    evaluate_callback = EvaluateCallback()\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=f'{model_save_dir}/{model_name}_{i}.h5',\n",
    "            save_best_only=True,\n",
    "            monitor='val_accuracy',\n",
    "            save_weights_only=True\n",
    "        ),\n",
    "        evaluate_callback\n",
    "    ]\n",
    "\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        epochs=epochs, \n",
    "        callbacks=callbacks,\n",
    "        validation_data=val_data)        \n",
    "    end = time.time()\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.plot(evaluate_callback.loss)\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.plot(evaluate_callback.accuracy)\n",
    "    plt.show()\n",
    "\n",
    "    model.load_weights(f'{model_save_dir}/{model_name}_{i}.h5')\n",
    "    test_loss, test_accuracy = model.evaluate(test_data)\n",
    "\n",
    "    fig = plt.figure(dpi=150)\n",
    "\n",
    "    counter = 0\n",
    "    for batch in test_data:\n",
    "        ims, labels = batch\n",
    "        preds = model.predict_on_batch(ims)\n",
    "\n",
    "        preds = tf.argmax(preds, 1)\n",
    "        at_cfm = tf.math.confusion_matrix(labels, preds, num_classes=len(events))\n",
    "\n",
    "        if counter == 0:\n",
    "            cfm = at_cfm\n",
    "        else:\n",
    "            cfm += at_cfm\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    cfm = cfm.numpy()\n",
    "    cfm = cfm.astype('float') / cfm.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(cfm, annot=True, fmt='.2f')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "    del model\n",
    "    keras.backend.clear_session()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
