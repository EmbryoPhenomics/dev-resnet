{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50205c7d-37d2-41d6-8965-87bb6f671856",
   "metadata": {},
   "source": [
    "# Training notebook for training and evaluating the an equivalent 2D version of Dev-ResNet: ResNet18 \n",
    "\n",
    "A notebook outlining the training and evaluation procedure for ResNet18, an equivalent residual CNN to Dev-ResNet. Note that this is specifically set up in terms of parameters for a dataset comprising developmental sequences of the great pond snail, Lymnaea stagnalis.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "The following are required dependencies for this script. We also set up mixed precision training for the speedup it provides in training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df9a002-cd53-4d47-9648-06f70ba8e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import vuba\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "import atexit\n",
    "import time\n",
    "import os\n",
    "import ujson\n",
    "import math\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "from resnet18 import ResNet18\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    \n",
    "# Parameters ----------------------------------------------------------\n",
    "batch_size = 32\n",
    "input_shape = (128, 128, 1)\n",
    "epochs = 50\n",
    "model_save_dir = './trained_models'\n",
    "events = ['pre_gastrula', 'gastrula', 'trocophore', 'veliger', 'eye', 'heart', 'crawling', 'radula', 'hatch', 'dead']\n",
    "\n",
    "train_data_path = './annotations_train_aug.csv'\n",
    "val_data_path = './annotations_val.csv'\n",
    "test_data_path = './annotations_test.csv'\n",
    "\n",
    "model_save_name = 'ResNet18_lymnaea'\n",
    "\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be0d6f9-93f4-418a-bd8d-193df3f379ca",
   "metadata": {},
   "source": [
    "Here we use the same dataset pipelines as in the training notebook for training the 3D-CNN, Dev-ResNet, except we select the first image from each GIF sequence for training the 2D-CNN, ResNet18 for model comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a486170b-489b-4633-86a7-a9d8fd584866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(fn, label):\n",
    "    gif = tf.io.read_file(fn)\n",
    "    gif = tf.image.decode_gif(gif)\n",
    "    gif = tf.image.resize_with_pad(gif, 128, 128)\n",
    "    gif = tf.image.rgb_to_grayscale(gif)\n",
    "    img = gif[0, ...] # Select first image for training ResNet18\n",
    "    return img, label\n",
    "\n",
    "def dataset(images, labels, batch_size): \n",
    "    data = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    data = data.map(read_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    data = data.batch(batch_size, drop_remainder=True)\n",
    "    return data\n",
    "\n",
    "annotations_train = pd.read_csv(train_data_path)\n",
    "annotations_train = annotations_train.sample(frac=1).reset_index(drop=True)\n",
    "annotations_train['categorical'] = [events.index(e) for e in annotations_train.single_event]\n",
    "\n",
    "annotations_val = pd.read_csv(val_data_path)\n",
    "annotations_val = annotations_val.sample(frac=1).reset_index(drop=True)\n",
    "annotations_val['categorical'] = [events.index(e) for e in annotations_val.single_event]\n",
    "\n",
    "annotations_test = pd.read_csv(test_data_path)\n",
    "annotations_test['categorical'] = [events.index(e) for e in annotations_test.single_event]\n",
    "\n",
    "# Training data pipeline\n",
    "train_files = list(annotations_train.out_file)\n",
    "train_labels = list(annotations_train.categorical)\n",
    "\n",
    "val_files = list(annotations_val.out_file)\n",
    "val_labels = list(annotations_val.categorical)\n",
    "\n",
    "# Test data pipeline\n",
    "test_files = list(annotations_test.out_file)\n",
    "test_labels = list(annotations_test.categorical)\n",
    "\n",
    "train_data = dataset(train_files, train_labels, batch_size)\n",
    "val_data = dataset(val_files, val_labels, batch_size)   \n",
    "test_data = dataset(test_files, test_labels, batch_size)\n",
    "\n",
    "for b in train_data:\n",
    "    images, labels = b\n",
    "    print(images.shape)\n",
    "    print(labels)\n",
    "    break\n",
    "\n",
    "# 4x4 grid for batch size of 32\n",
    "fig = plt.figure(figsize=(8., 8.))\n",
    "grid = ImageGrid(fig, 111,\n",
    "             nrows_ncols=(4, 4),\n",
    "             axes_pad=0.3,\n",
    ")\n",
    "\n",
    "for i, (v, f, ax) in enumerate(zip(images, labels, grid)):\n",
    "\n",
    "    im = v[:,:,0]\n",
    "    event = events[f]\n",
    "    \n",
    "    ax.set_title(event)\n",
    "    ax.imshow(im, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74c66a7-108f-4362-8175-78a7f5f97533",
   "metadata": {},
   "source": [
    "The main training loop for ResNet18 with images of *Lymnaea stagnalis* embryos. This is exactly the same pipeline as used for Dev-ResNet including hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deba17d-0ce5-44b3-9d9b-3244d387fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate with three different seeds for computing metrics\n",
    "for i in range(3):\n",
    "    np.random.seed(i)\n",
    "    tf.random.set_seed(i)\n",
    "    \n",
    "    model = ResNet18(input_shape, n_classes=len(events))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.000001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    class EvaluateCallback(keras.callbacks.Callback):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.loss = []\n",
    "            self.accuracy = []\n",
    "\n",
    "        def on_epoch_end(self, epoch, log=None):\n",
    "            loss, acc = self.model.evaluate(test_data, verbose=0)\n",
    "            print('-', 'test_loss:', round(loss, 4), 'test_accuracy:', round(acc, 4))\n",
    "            self.loss.append(loss)\n",
    "            self.accuracy.append(acc)\n",
    "\n",
    "    evaluate_callback = EvaluateCallback()\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=f'{model_save_dir}/{model_save_name}_{i}.h5',\n",
    "            save_best_only=True,\n",
    "            monitor='val_accuracy',\n",
    "            save_weights_only=True\n",
    "        ),\n",
    "        evaluate_callback\n",
    "    ]\n",
    "\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        epochs=epochs, \n",
    "        callbacks=callbacks,\n",
    "        validation_data=val_data)        \n",
    "    end = time.time()\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.plot(evaluate_callback.loss)\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.plot(evaluate_callback.accuracy)\n",
    "    plt.show()\n",
    "\n",
    "    model.load_weights(f'{model_save_dir}/{model_save_name}_{i}.h5')\n",
    "    test_loss, test_accuracy = model.evaluate(test_data)\n",
    "\n",
    "    fig = plt.figure(dpi=150)\n",
    "\n",
    "    counter = 0\n",
    "    for batch in test_data:\n",
    "        ims, labels = batch\n",
    "        preds = model.predict_on_batch(ims)\n",
    "\n",
    "        preds = tf.argmax(preds, 1)\n",
    "        at_cfm = tf.math.confusion_matrix(labels, preds, num_classes=len(events))\n",
    "\n",
    "        if counter == 0:\n",
    "            cfm = at_cfm\n",
    "        else:\n",
    "            cfm += at_cfm\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    cfm = cfm.numpy()\n",
    "    cfm = cfm.astype('float') / cfm.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(cfm, annot=True, fmt='.2f')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "    del model\n",
    "    keras.backend.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
