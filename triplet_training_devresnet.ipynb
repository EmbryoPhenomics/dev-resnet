{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd6326f6-7e69-4466-8e09-383d8a1b29d2",
   "metadata": {},
   "source": [
    "# Notebook for training Dev-ResNet with Triplet Semi-Hard loss\n",
    "\n",
    "A notebook outlining the training and inference process for Dev-ResNet with Triplet Semi-Hard loss, for the purpose of visualising the differences between detected features in high-dimensional space between developmental events. Note that the shape of the continuum will look slightly different each run because the random seeds used internally are not set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b9a6b-cec1-448d-aea9-35dd2b6ddc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import vuba\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "import atexit\n",
    "import time\n",
    "import os\n",
    "import ujson\n",
    "import math\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "from dev_resnet import DevResNet\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    \n",
    "# Parameters ----------------------------------------------------------\n",
    "batch_size = 16\n",
    "input_shape = (12, 128, 128, 1)\n",
    "epochs = 50\n",
    "model_save_dir = './trained_models'\n",
    "events = ['pre_gastrula', 'gastrula', 'trocophore', 'veliger', 'eye', 'heart', 'crawling', 'radula', 'hatch', 'dead']\n",
    "\n",
    "# Labels used for plotting below\n",
    "act_events = ['Pre-Gastrula', 'Gastrula', 'Trochophore', 'Veliger', 'Eye spots', 'Heart beat', 'Crawling', 'Radula', 'Hatch', 'Dead']\n",
    "\n",
    "train_data_path = './annotations_train_aug.csv'\n",
    "val_data_path = './annotations_val.csv'\n",
    "test_data_path = './annotations_test.csv'\n",
    "\n",
    "model_save_name = 'Dev-Resnet_lymnaea_TripLet'\n",
    "\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf97b83e-84c3-4648-9800-d9a0f1d960e1",
   "metadata": {},
   "source": [
    "# Dataset handling\n",
    "\n",
    "Here we use the same dataset pipelines as in the training notebook for training the original 3D-CNN, Dev-ResNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7366e7-b5c0-494e-8946-da61c2f28255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "def read_data(fn, label):\n",
    "    gif = tf.io.read_file(fn)\n",
    "    gif = tf.image.decode_gif(gif)\n",
    "    gif = tf.image.resize_with_pad(gif, 128, 128)\n",
    "    gif = tf.image.rgb_to_grayscale(gif)\n",
    "    return gif, label\n",
    "\n",
    "def dataset(images, labels, batch_size): \n",
    "    data = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    data = data.map(read_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    data = data.batch(batch_size, drop_remainder=False)\n",
    "    return data\n",
    "\n",
    "annotations_train = pd.read_csv(train_data_path)\n",
    "annotations_train = annotations_train.sample(frac=1).reset_index(drop=True)\n",
    "annotations_train['categorical'] = [events.index(e) for e in annotations_train.single_event]\n",
    "\n",
    "annotations_val = pd.read_csv(val_data_path)\n",
    "annotations_val = annotations_val.sample(frac=1).reset_index(drop=True)\n",
    "annotations_val['categorical'] = [events.index(e) for e in annotations_val.single_event]\n",
    "\n",
    "annotations_test = pd.read_csv(test_data_path)\n",
    "annotations_test['categorical'] = [events.index(e) for e in annotations_test.single_event]\n",
    "\n",
    "# Training data pipeline\n",
    "train_files = list(annotations_train.out_file)\n",
    "train_labels = list(annotations_train.categorical)\n",
    "\n",
    "val_files = list(annotations_val.out_file)\n",
    "val_labels = list(annotations_val.categorical)\n",
    "\n",
    "# Test data pipeline\n",
    "test_files = list(annotations_test.out_file)\n",
    "test_labels = list(annotations_test.categorical)\n",
    "\n",
    "train_data = dataset(train_files, train_labels, batch_size)\n",
    "val_data = dataset(val_files, val_labels, batch_size)   \n",
    "test_data = dataset(test_files, test_labels, batch_size)\n",
    "\n",
    "for b in train_data:\n",
    "    images, labels = b\n",
    "    print(images.shape)\n",
    "    print(labels)\n",
    "    break\n",
    "\n",
    "# 4x4 grid for batch size of 32\n",
    "fig = plt.figure(figsize=(8., 8.))\n",
    "grid = ImageGrid(fig, 111,\n",
    "             nrows_ncols=(4, 4),\n",
    "             axes_pad=0.3,\n",
    ")\n",
    "\n",
    "for i, (v, f, ax) in enumerate(zip(images, labels, grid)):\n",
    "\n",
    "    im = v[0,:,:,0]\n",
    "    event = events[f]\n",
    "    \n",
    "    ax.set_title(event)\n",
    "    ax.imshow(im, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7441059-33b9-4916-a2a5-639e599af909",
   "metadata": {},
   "source": [
    "# Instantiate and compile model for training with Triplet Semi-Hard loss\n",
    "\n",
    "Here we replace the final classification block in Dev-ResNet with a fully connected layer with L2 normalization for training with triplet semi-hard loss. We only train the model 20 epochs rather than the original 50, since 20 is sufficient to reach conversion for this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3852b7-ea2a-40bf-81be-96b06fc0c938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducible results\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "# Instantiate and compile modified Dev-ResNet network for training with Triplet loss\n",
    "inputs = keras.Input(input_shape)\n",
    "model = DevResNet(input_tensor=inputs, include_top=False)\n",
    "\n",
    "# Add fully connected final layer without classification head\n",
    "x = layers.GlobalAveragePooling3D()(model.output)\n",
    "x = layers.BatchNormalization()(x)  \n",
    "x = layers.Dense(512)(x)   \n",
    "x = tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=tfa.losses.TripletSemiHardLoss()\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f'{model_save_dir}/{model_save_name}.h5',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=20, \n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_data)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab3d231-6631-47a5-a91d-d1ccdabe2def",
   "metadata": {},
   "source": [
    "# Evaluate on test data and visualise using UMAP\n",
    "\n",
    "Here we evaluate the trained model on the testing data before performing dimesionality reduction using UMAP for 2D visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f37a33-4034-496b-9029-3be18cc13680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the network on unseen testing data\n",
    "results = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2870231-841b-42d8-b6e3-e7f8bd35e56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "\n",
    "results_scaled = StandardScaler().fit_transform(results)\n",
    "trans = reducer.fit(results_scaled)\n",
    "embedding = trans.transform(results_scaled).\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fda1f7-29c3-489c-9565-37857bad0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "plt.style.use('default')\n",
    "\n",
    "cmap = matplotlib.colormaps.get_cmap('plasma')\n",
    " \n",
    "fig, ax1 = plt.subplots(dpi=150, figsize=(9,9))\n",
    "\n",
    "for i in sorted(pd.unique(test_labels)):\n",
    "    ax1.plot(-2.5, 0, 'o', markersize=2, label=act_events[i])\n",
    "\n",
    "for i,e in enumerate(embedding):\n",
    "    ax1.plot(e[0], e[1], 'o', markersize=2, color=f'C{test_labels[i]}')\n",
    "\n",
    "ax1.legend(title='Developmental event:')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
